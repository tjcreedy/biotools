#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 16 13:36:06 2020

@author: thomas
"""

# Imports

import os
import sys
import argparse
import csv
import statistics
from collections import defaultdict, Counter
#import os
import re
#import subprocess

from Bio.SeqIO.FastaIO import SimpleFastaParser
import textwrap as _textwrap

#from Bio import SeqIO

# Function definitions

# Class definitions

class MultilineFormatter(argparse.HelpFormatter):
    def _fill_text(self, text, width, indent):
        text = self._whitespace_matcher.sub(' ', text).strip()
        paragraphs = text.split('|n ')
        multiline_text = ''
        for paragraph in paragraphs:
            formatted_paragraph = (_textwrap.fill(paragraph, width, 
                                                 initial_indent=indent, 
                                                 subsequent_indent=indent) 
                                   + '\n\n')
            multiline_text = multiline_text + formatted_paragraph
        return multiline_text

class Range(object):
    def __init__(self, start, end):
        self.start = start
        self.end = end
    def __eq__(self, other):
        return self.start <= other <= self.end

class MinimumInteger(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        if values < 0:
            parser.error("Minimum value for {0} is 1".format(option_string))
        setattr(namespace, self.dest, values)

# Global variables

wellregex = '([A-H])([1-9]|0[1-9]|1[0-2])'
directregex = '(R)([12])'

# Arguments

parser = argparse.ArgumentParser(description="""
    description:
    |n
    Integrate the results of searching an OTU/ASV file against a local set of 
    references into the OTU/ASV file and a read mapping table. Three inputs are 
    required: a --fasta of OTU/ASV sequences with unique names, the results of 
    a --usearch run of the --fasta against a reference db (uc format) and a 
    --table mapping reads to the OTUs/ASVs as generated by vsearch --otutabout. 
    The corrected fasta and reads table will be written out with the --prefix 
    'refmerge_' by default.
    |n
    The names of reference sequences will be taken as the string from the start
    of the header to any space or ;: characters. If present, the sample name 
    from which the reference can be detected in the reference header if the 
    format is ';sample=SAMPLENAME'. The references file may contain duplicate 
    sequences or multiple sequences with the same reference name, for the 
    purposes of read correction, however it is important that sequences from 
    the same species share the same name. 
    |n
    By default, any hits of greater than 99 percent identity will be accepted;
    this threshold can be modified using --identity. For each OTU, any hits 
    against references with the same name will be treated as a single hit with
    the highest percent identity of the group for the purposes of assigning 
    names. If there are multiple hits against references with different names,
    the reference name with the highest identity will be taken; if the 
    identities are equal, no reference name will be taken.
    |n
    If multiple OTUs/ASVs have as their top identity the same reference name, 
    these OTUs/ASVs will be merged, taking the sequence of the first OTU (based
    on a numerical sort of numbers at the end of from sequence names). This
    behaviour can be turned off using the --donotmerge flag, in which case the
    OTU/ASV with the highest identity will take the name of that reference and
    any other OTUs will take no name; or, if any hit with equal identity, none
    will take the name. The read numbers of any merged OTUs/ASVs will be summed
    .
    |n
    If references were drawn from the same samples as were used to generate the
    OTUs/ASVs, and the sample name is included in the reference header, the
    script can, using the optional --editreads flag, edit the reads mapping
    table to increase the number of mapped reads for this OTU/ASV in the named
    sample, if SAMPLENAME is present in the mapping table. If --editreads is
    supplied without an argument, the value used will be equal to the rounded 
    average number of reads per OTU/ASV per sample.
    """, formatter_class=MultilineFormatter)

parser._optionals.title = "arguments"

parser.add_argument("-f", "--fasta", 
                    help = "a fasta file of OTU or ASV sequences", 
                    type = str, metavar = "X", required = True)
parser.add_argument("-u", "--usearch", 
                    help = """a .uc file reporting the results of searching the
                    OTUs against your references""", 
                    type = str, metavar = "X", required = True)
parser.add_argument("-t", "--table", 
                    help = """a vsearch --otutabout format file mapping your 
                    reads to your OTU --fasta""", 
                    type = str, metavar = "X", required = True)
parser.add_argument("-i", "--identity", 
                    help = """threshold identity below which to reject
                    reference matches""",
                    type = float, metavar = "N", default = 99, 
                    choices=[Range(0,100)])
parser.add_argument("-d", "--dontmerge", 
                    help = """do not merge OTUs/ASVs with multiple top-hit
                    reference matches, take the highest""",
                    action = 'store_true')
parser.add_argument("-e", "--editreads", help = """edit read counts to reflect
                    the presence of a match""", 
                    metavar = "[N]", type = int, nargs = '?', 
                    default = None, const = 0, action=MinimumInteger)
parser.add_argument("-p", "--prefix", 
                    help = "prefix for output files", 
                    metavar = "X", type = str, default = "refmerge_")


# Main

if __name__ == "__main__":
    
    args = parser.parse_args()
    #os.chdir('../testingdata/CCCPsub/')
    #args = parser.parse_args("-f otus.fasta -u dummy.uc -t reads.tsv -e".split(' '))
    
    # Parse the UC file
    
    usearch_parse = defaultdict(list)
    
    with open(args.usearch, 'r') as uc_file:
        #uc_file =  open(args.usearch, 'r')
        #close(tab_file)
            for n, row in enumerate(csv.reader(uc_file, delimiter = '\t')):
                #n, row = list(enumerate(csv.reader(uc_file, delimiter = '\t')))[0]
                n = str(n+1)
                if len(row) != 10:
                    sys.exit(("Error: line %s of %s does not contain 10 ",
                              "elements are you sure this is a .uc file?\n" % 
                              (str(n), args.usearch)))
                if row[0] not in ['H','N']:
                    sys.exit(("Error: line %s of %s is not a Hit or No hit, "
                              "are you sure this is the correct .uc file?\n" %
                              (str(n), args.usearch)))
                
                mid = float(row[3]) if row[0] is 'H' else 0
                
                if row[0] is 'H' and mid >= args.identity:
                    otu = row[8]
                    n = re.split('[:;\s]', row[9])[0]
                    s = re.search(';sample=[^;:\s]+', row[9]).group()[8:]
                    usearch_parse[otu].append([n, s, mid])
    
    # Assess usearch results
    
    matches = dict()
    
    for otu, match in usearch_parse.items():
        #otu='otu1'
        #match=usearch_parse[otu]
        
        # Find the name(s) of the top match(es) for this OTU
        maxmatch = max([m[2] for m in match])
        top_names = set([m[0] for m in match if m[2] == maxmatch])
        
        if len(top_names) == 1:
            name = list(top_names)[0]
            samples = [m[1] for m in match if m[0] == name]
            
            if name in matches:
                matches[name]['otus'].append(otu)
                matches[name]['id'].append(maxmatch)
                matches[name]['samples'].extend(samples)
            else:
                matches[name] = {'otus': [otu],
                             'id': [maxmatch],
                             'samples': samples}
    
    
    # Generate instructions for fasta output and read map editing
    fastaedits = dict()
    mapedits = dict()
    
    for ref, details in matches.items():
        #ref, details = list(matches.items())[0]
        
        if args.dontmerge:
                # Remove matches of otus to reference that are not the top hit
                    # Find the highest hit index
                maxmatch = max(details['id'])
                top_i = [i for i, m in enumerate(details['id']) 
                         if m == maxmatch]
                
                if len(top_i) == 1:
                    # If there is only one, reduce the dict of list down to
                    # just that one hit
                    top_i = top_i[0]
                    details = {k:[details[k][top_i]] for k in details.keys()}
                    
                else:
                    # Otherwise remove all hits
                    details = {k:[] for k in details.keys()}
        
        # If there are any OTUs remaining (i.e. if dontmerge is invoked and was
        # able to decide on a single match, or dontmerge is not invoked)
        if len(details['otus']) > 0:
            # Find the OTU with the lowest number at the end of the
            # name (i.e. most frequent OTU)
            min_i = 0
            if len(details['otus']) > 1:
                otun = [int(re.search('\d+$', o).group()) for o in details['otus']]
                min_i = [i for i, n in enumerate(otun) if n == min(otun)][0]
            
            for i, o in enumerate(details['otus']):
                # Set that OTU to be renamed to the reference, otherwise to be 
                # deleted
                
                if i == min_i:
                    fastaedits[o] = ref
                    mapedits[o] = {'ref': ref, 'merge': details['otus'],
                                   'samples': Counter(details['samples'])}
                    
                else:
                    fastaedits[o] , mapedits[o] = [None, None]
                    
    
    # Correct fasta
    with open(args.fasta) as infasta, \
         open(args.prefix + args.fasta, "w") as outfasta:
        
        for head, seq in SimpleFastaParser(infasta):
            outhead = head
            if head in fastaedits.keys():
                if fastaedits[head] is None:
                    continue
                else:
                    outhead = fastaedits[head]
            outfasta.write(">%s\n%s\n" % (outhead, seq))
    
    # Correct reads table
    
    
    # Read in the table
    readtab = dict()
    samples = []
    allcounts = []
    with open(args.table) as intable:
        #intable = open(args.table)
        n = 0
        coln = 0
        for n, row in enumerate(csv.reader(intable, delimiter = '\t')):
            #n, row = list(enumerate(csv.reader(intable, delimiter = '\t')))[1]
            n += 1
            if n == 1: 
                coln = len(row)
                samples = row[1:]
            elif len(row) != coln:
                sys.exit(("Error: line %s of %s does not contain %s elements, "
                          "are you sure this is a the correct file?\n" % 
                          (str(n), args.table, str(coln))))
            else:
                counts = [int(c) for c in row[1:]]
                readtab[row[0]] = counts
                allcounts.extend(counts)
    
    # Get the replacement value
    rval = None
    if args.editreads:
        rval = (round(statistics.mean(counts)) if args.editreads == 0 
                else args.editreads)
    
    # Do replacement
    for otu, edits in mapedits.items():
        # otu, edits = list(mapedits.items())[0]
        if not edits: continue
        
        if len(edits['merge']) > 1:
            allreads = [readtab[o] for o in edits['merge']]
            readtab[o] = list(map(sum, zip(*allreads)))
        
        if args.editreads:
            for s, c in edits['samples'].items():
                si = samples.index(s)
                readtab[o][si] += rval * c
    
    # Write out reads
    with open(args.prefix + args.table, 'w') as outtable:
        ot = csv.writer(outtable, delimiter = '\t', quotechar = '',
                        quoting = csv.QUOTE_NONE, escapechar = '')
        
        # Write header
        ot.writerow(['#OTU ID'] + samples)
        
        # Write reads
        for otu, reads in readtab.items():
            outname = otu
            if otu in mapedits:
                if mapedits[otu]:
                    outname = mapedits[otu]['ref']
            
            ot.writerow([outname] + reads)
    
    exit()
